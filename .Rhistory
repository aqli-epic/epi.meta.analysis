# joining the world shape + epi joined file with the aqli color file
world_shp_epi_color <- world_shp_epi %>%
left_join(aqli_color_country, by = "country") %>%
filter(country != "Antarctica") %>%
select(country, num_studies, avg_pm2.5_2020, geometry)
# In the total number of studies column, replacing NAs with 0s
world_shp_epi_color <- world_shp_epi_color %>%
mutate(num_studies = ifelse(is.na(num_studies) == TRUE, 0, num_studies))
# getting centroids for countries after correcting for problematic polygons
world_shp_epi_color_for_centroids <- st_make_valid(world_shp_epi_color)
country_wise_centroids <- st_centroid(world_shp_epi_color_for_centroids, of_largest_polygon = TRUE)
# plotting the choropleth
geographic_dist_graph <- world_shp_epi_color %>%
ggplot() +
geom_sf(mapping = aes(fill = avg_pm2.5_2020), color = "white") +
scale_fill_continuous_sequential(palette = "YlOrRd") +
geom_sf(data = country_wise_centroids %>% filter(num_studies != 0), mapping = aes(size = num_studies), col = "grey", ) +
theme(legend.position = "bottom") +
scale_size_binned() +
scale_size(range = c(0, 8)) +
theme_map() +
theme(legend.position = "bottom")
#> Other calculations for this block of code
# total number of studies performed in USA and Canada
num_studies_usa_canada <- epi_country_count %>%
filter(country %in% c("United States", "Canada")) %>%
summarise(total_studies = sum(n, na.rm = TRUE)) %>%
unlist()
# total number of studies performed in USA and Canada and Europe
num_studies_usa_canada_europe <- epi %>%
filter((country %in% c("Canada", "USA")) | (continent %in% c("Europe"))) %>%
nrow()
# areas other than USA, Canada and Europe
areas_other_than_usa_canada_europe <- epi %>%
filter((country %notin% c("Canada", "USA")) & (continent %notin% c("Europe"))) %>%
select(country) %>%
unique() %>%
unlist() %>%
as.vector()
# continent order list (order variable: number of studies)
continent_wise_study_summary <- epi %>%
group_by(continent) %>%
summarise(count = n(), average_study_duration = mean(study_duration, na.rm = TRUE)) %>%
slice_max(count, n = 6) %>%
mutate(prop_studies = round((count/sum(count, na.rm = TRUE))*100, 1))
# total number of studies in South America
num_studies_south_america <- epi %>%
filter(continent == "South America") %>%
nrow()
# total number of studies in Oceania
num_studies_oceania <- epi %>%
filter(continent == "Oceania") %>%
nrow()
# total number of studies in Africa
num_studies_africa <- epi %>%
filter(continent == "Africa") %>%
nrow()
# plot geographic distribution
geographic_dist_graph
#> Add a note mentioning that the underlying data for this graph includes all types of pollutants but only one row is counted for a given pooled (multi-country) study.
epi %>%
dplyr::distinct(paper_uid, .keep_all = TRUE) %>%
group_by(publishing_year) %>%
summarise(total_studies = n()) %>%
ungroup() %>%
filter(total_studies != "NA", !is.na(total_studies), publishing_year != "NA", !is.na(publishing_year)) %>%
ggplot() +
geom_line(mapping = aes(x = publishing_year, y = total_studies), lwd = 1.2, color = "cornflowerblue") +
labs(x = "Year", y = "Total Number of Studies") +
theme_minimal()
#>  In this, in the graph multiple countries of a pooled study are counted separately. Also, this is not a PM2.5 specific graph.
#> Density plot of study duration (commented for now, can use later if required)
# epi %>%
#   filter(!is.na(study_duration)) %>%
#   ggplot() +
#   geom_density(mapping = aes(x = study_duration, fill = continent), alpha = 0.5) +
#     labs(x = "Study Duration") +
#   ggtitle("Epi Studies Duration Distribution (Continent Wise): Density Plot") +
#   scale_x_continuous(breaks = seq(0, 40, 5)) +
#   theme_tufte() +
#   theme(legend.position = "bottom")
#> Histogram of study duration
# adding an order panel
continent_wise_study_duration_graph <- epi %>%
dplyr::filter(continent != "NA", !is.na(continent)) %>%
mutate(order_continent = ifelse(continent == "Asia", 1, 0),
order_continent = ifelse(continent == "Europe", 2, order_continent),
order_continent = ifelse(continent == "North America", 3, order_continent),
order_continent = ifelse(continent == "South America", 4, order_continent),
order_continent = ifelse(continent == "Africa", 5, order_continent),
order_continent = ifelse(continent == "Oceania", 6, order_continent)) %>%
ggplot() +
geom_histogram(mapping = aes(x = study_duration, fill = continent), alpha = 0.5, color = "white", position = "identity", binwidth = 2) +
labs(x = "Study Duration") +
ggtitle("Epi Studies Duration Distribution (Continent Wise): Histogram") +
scale_x_continuous(breaks = seq(0, 40, 10)) +
theme_hc() +
theme(legend.title = element_blank()) +
facet_wrap(~fct_reorder(continent, order_continent), nrow = 1) +
theme(axis.line.y = element_line(color = "black"),
axis.line.x = element_line(color = "black"))
#> calculations relevant for this block of code
# long term study threshold
long_term_study_duration <- 25
# countries with studies greater than x (long_term) years of study duration
epi_long_term_studies_countries <- epi %>%
filter(study_duration > long_term_study_duration, study_duration != "NA", !is.na(study_duration)) %>%
select(country) %>%
unlist() %>%
unique()
# continent order list (order variable: number of studies): code present in the geographical distribution map block.
# plot continent wise study duration graph
continent_wise_study_duration_graph
#### Country wise Distribution of Study Duration (Density and Histogram Plots)
#> Different countries in a pooled study should be counted separately. As of now this is PM2.5 specific, but can be generalized in the future.
#> (9) Country wise Study duration density plot
epi %>%
filter(!is.na(mean_pm2.5), mean_pm2.5 != "NA", non_pm2.5 == 0, !is.na(study_duration), study_duration != "NA") %>%
ggplot() +
geom_density(mapping = aes(x = study_duration, fill = country, alpha = 0.5)) +
theme_tufte()
#> Country Wise Study Duration histogram
epi %>%
filter(!is.na(mean_pm2.5), mean_pm2.5 != "NA", non_pm2.5 == 0, !is.na(study_duration), study_duration != "NA") %>%
ggplot() +
geom_histogram(mapping = aes(x = study_duration, fill = country, alpha = 0.5), position = "identity", alpha = 0.5, color = "white", binwidth = 1) +
theme_tufte() +
facet_wrap(~country, nrow = 5) +
theme(legend.position = "bottom")
# loading the .RData file that contain all required data objects
save(list = ls(all = TRUE), file= "all.RData")
runApp()
?ggplotly
runApp()
epi %>% filter(study_duration > 1, cohort_size > 1000) %>% nrow()
epi %>% filter(study_duration > 1, cohort_size > 1000) %>% View()
epi %>% filter(study_duration > 1, cohort_size > 1000) %>% distinct(paper_uid)
epi %>% filter(study_duration > 1, cohort_size > 1000) %>% distinct(paper_uid, .keep_all = TRUE) %>% summarise(tot_pm2.5 = 69 - sum(non_pm2.5))
foo <- epi %>% filter(study_duration > 1, cohort_size > 1000) %>% distinct(paper_uid, .keep_all = TRUE)
foo
foo$paper_type
install.packages("titling")
knit_with_parameters("C:/Users/Aarsh/Desktop/aqli-epic/epi.meta.analysis/README.Rmd")
# epi studies analysis raw sheet
epi <- readxl::read_xlsx("./data-raw/pm2.5_distribution/AQLI_Epidemiology Literature Research.xlsx", sheet = "AnalysisDatasetPM2.5MortalityAn")
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>",
fig.path = "man/figures/README-",
out.width = "100%"
)
# load libraries
library(readr)
library(dplyr)
library(stringr)
library(magrittr)
library(ggplot2)
library(readr)
library(tidytext)
library(tidyr)
library(tidyverse)
library(ggthemes)
library(sf)
library(rnaturalearth)
library(rnaturalearthdata)
library(mapsf)
library(colorspace)
library(shiny)
library(shinydashboard)
#> read in datasets
# pooled study branch
# global variables
who_pm2.5_guideline <- 5
# epi studies analysis raw sheet
epi <- readxl::read_xlsx("./data-raw/pm2.5_distribution/AQLI_Epidemiology Literature Research.xlsx", sheet = "AnalysisDatasetPM2.5MortalityAn")
# AQLI color file
aqli_color <- read_csv("./data-raw/pm2.5_distribution/color.csv")
# global operations
`%notin%` <- Negate(`%in%`)
#> change default columns types
epi$cohort_size <- as.numeric(epi$cohort_size)
epi$study_start_year<- as.numeric(epi$study_start_year)
epi$study_end_year <- as.numeric(epi$study_end_year)
epi$pm2.5_exposure_ll <- as.numeric(epi$pm2.5_exposure_ll)
epi$pm2.5_exposure_ul <- as.numeric(epi$pm2.5_exposure_ul)
epi$mean_pm2.5 <- as.numeric(epi$mean_pm2.5)
epi$sd_pm2.5 <- as.numeric(epi$sd_pm2.5)
epi$cohort_age_ll <- as.numeric(epi$cohort_age_ll)
epi$cohort_age_ul <- as.numeric(epi$cohort_age_ul)
#> add useful columns and filter out some studies (e.g. pooled studies, meta analysis, other parameter based filtering)
epi <- epi %>%
mutate(study_duration = study_end_year - study_start_year)
#> setting report parameters
min_cohort_size <- 1000
min_study_duration_in_years <- 1
#> Filtering the epi database (minimum cohort size: >1000, minimum study duration: > 1 year): commented for now.
# epi <- epi %>%
#   mutate(study_duration = (study_end_year - study_start_year) + 1) %>%
#   filter(cohort_size > 1000, study_duration > 1)
#> Calculations needed for all sections above the "Results section".
# percent of population not in compliance with the WHO guideline
num_people_above_who <- aqli_color %>%
filter(pm2020 > who_pm2.5_guideline) %>%
summarise(tot_pop = sum(population, na.rm = TRUE)) %>%
unlist()
# world population
world_pop <- aqli_color %>%
summarise(tot_pop = sum(population, na.rm = TRUE)) %>%
unlist()
percent_people_above_who <- round((num_people_above_who/world_pop)*100, 1)
#> mean pm2.5 distribution segregated by country (density plot): makes sense to count different country studies separately, as we are making country wise distributions, so we want to see all PM2.5 ranges covered in a given country.
mean_pm2.5_country_wise_graph <- epi %>%
filter(!is.na(mean_pm2.5), mean_pm2.5 != "NA", non_pm2.5 == 0) %>%
ggplot() +
geom_density(mapping = aes(x = mean_pm2.5, fill = country), alpha = 0.5, color = "black", position = "identity") +
labs(x = expression(paste("Mean PM2.5 concentration (", mu, "g", "/", m^3, ")"))) +
theme_tufte()
mean_pm2.5_country_wise_graph
# aqli color population in ordered pm2.5 buckets
aqli_color_grp_pm2.5_buckets <- aqli_color %>%
mutate(region = ifelse(pm2020 >= 0 & pm2020 <= 25, "0-25", pm2020),
region = ifelse(pm2020 > 25 & pm2020 <= 50, ">25-50", region),
region = ifelse(pm2020 > 50 & pm2020 <= 75, ">50-75", region),
region = ifelse(pm2020 > 75 & pm2020 <= 100, ">75-100", region),
region = ifelse(pm2020 > 100, ">100", region)) %>%
group_by(region) %>%
summarise(tot_pop = sum(population, na.rm = TRUE)) %>%
ungroup() %>%
mutate(order_pollution_group = ifelse(region == "0-25", 1, 0),
order_pollution_group = ifelse(region == ">25-50", 2, order_pollution_group),
order_pollution_group = ifelse(region == ">50-75", 3, order_pollution_group),
order_pollution_group = ifelse(region == ">75-100", 4, order_pollution_group),
order_pollution_group = ifelse(region == ">100", 5, order_pollution_group)) %>%
ungroup() %>%
mutate(tot_pop_prop = (tot_pop/sum(tot_pop))*100)
aqli_color_grp_pm2.5_buckets
# epi total number of studies in ordered pollution buckets (makes sense to count different countries in a pooled study as different studies)
epi_num_studies_grp_pm2.5_buckets <- epi %>%
filter(!is.na(mean_pm2.5) , mean_pm2.5 != "NA", non_pm2.5 == 0) %>%
mutate(region = ifelse(mean_pm2.5 >= 0 & mean_pm2.5 <= 25, "0-25", mean_pm2.5),
region = ifelse(mean_pm2.5 > 25 & mean_pm2.5 <= 50, ">25-50", region),
region = ifelse(mean_pm2.5 > 50 & mean_pm2.5 <= 75, ">50-75", region),
region = ifelse(mean_pm2.5 > 75 & mean_pm2.5 <= 100, ">75-100", region),
region = ifelse(mean_pm2.5 > 100, ">100", region)) %>%
mutate(order_pollution_group = ifelse(region == "0-25", 1, 0),
order_pollution_group = ifelse(region == ">25-50", 2, order_pollution_group),
order_pollution_group = ifelse(region == ">50-75", 3, order_pollution_group),
order_pollution_group = ifelse(region == ">75-100", 4, order_pollution_group),
order_pollution_group = ifelse(region == ">100", 5, order_pollution_group)) %>%
group_by(region) %>%
summarise(tot_studies = n(), order_pollution_group = order_pollution_group[1]) %>%
ungroup() %>%
mutate(tot_studies_prop = (tot_studies/sum(tot_studies))*100)
epi_num_studies_grp_pm2.5_buckets
epi$paper_type
1 %in% c(1, 2)
c(1, 2) > 1
aqli_color
aqli_color %>% group_by(country) %>% mutate(pop_weights = population/sum(population, na.rm = TRUE), pm2020_pop_weighted = pm2020*pop_weights) %>% summarise(avg_pm2.5_2020 = sum(pm2020_pop_weighted, na.rm = TRUE))
foo <- aqli_color %>% group_by(country) %>% mutate(pop_weights = population/sum(population, na.rm = TRUE), pm2020_pop_weighted = pm2020*pop_weights) %>% summarise(avg_pm2.5_2020 = sum(pm2020_pop_weighted, na.rm = TRUE))
foo
foo %>% slice_max(avg_pm2.5_2020, n = 10) %>% View()
foo %>% slice_max(avg_pm2.5_2020, n = 10) %>% select(country) %>% unlist() %>% as.vector()
foo %>% slice_max(avg_pm2.5_2020, n = 10) %>% select(country) %>% unlist() %>% as.vector()
aqli_color %>% slice_max(pm2020, n = 10)
aqli_color %>% slice_max(pm2020, n = 10) %>% select(country) %>% unlist() %>% as.vector()
aqli_color %>% slice_max(pm2020, n = 10) %>% select(name_2) %>% unlist() %>% as.vector()
aqli_color %>% slice_max(pm2020, n = 10) %>% select(name_1, name_2)
aqli_color %>% group_by(name_1) %>% mutate(pop_weights = population/sum(population, na.rm = TRUE), pm2020_pop_weighted = pm2020*pop_weights) %>% summarise(avg_pm2.5_2020 = sum(pm2020_pop_weighted, na.rm = TRUE))
aqli_color %>% group_by(name_1) %>% mutate(pop_weights = population/sum(population, na.rm = TRUE), pm2020_pop_weighted = pm2020*pop_weights) %>% summarise(avg_pm2.5_2020 = sum(pm2020_pop_weighted, na.rm = TRUE)) %>% slice_max(avg_pm2.5_2020, n = 10)
aqli_color %>% slice_max(pm2020, n = 10) %>% select(name_1, name_2)
epi %>%
filter(!is.na(mean_pm2.5), mean_pm2.5 != "NA", non_pm2.5 == 0) %>%
group_by(paper_uid) %>%
summarise(mean_pm2.5 = mean(mean_pm2.5, na.rm = TRUE))
# epi total number of studies in ordered pollution buckets (initially filtering out pooled studies, will add back in using a for loop)
epi_num_studies_grp_pm2.5_buckets <- epi %>%
filter(!is.na(mean_pm2.5), mean_pm2.5 != "NA", non_pm2.5 == 0) %>%
group_by(paper_uid) %>%
summarise(mean_pm2.5 = mean(mean_pm2.5, na.rm = TRUE)) %>%
mutate(region = ifelse(mean_pm2.5 >= 0 & mean_pm2.5 <= 25, "0-25", mean_pm2.5),
region = ifelse(mean_pm2.5 > 25 & mean_pm2.5 <= 50, ">25-50", region),
region = ifelse(mean_pm2.5 > 50 & mean_pm2.5 <= 75, ">50-75", region),
region = ifelse(mean_pm2.5 > 75 & mean_pm2.5 <= 100, ">75-100", region),
region = ifelse(mean_pm2.5 > 100, ">100", region)) %>%
mutate(order_pollution_group = ifelse(region == "0-25", 1, 0),
order_pollution_group = ifelse(region == ">25-50", 2, order_pollution_group),
order_pollution_group = ifelse(region == ">50-75", 3, order_pollution_group),
order_pollution_group = ifelse(region == ">75-100", 4, order_pollution_group),
order_pollution_group = ifelse(region == ">100", 5, order_pollution_group)) %>%
group_by(region) %>%
summarise(tot_studies = n(), order_pollution_group = order_pollution_group[1]) %>%
ungroup() %>%
mutate(tot_studies_prop = (tot_studies/sum(tot_studies))*100)
epi_num_studies_grp_pm2.5_buckets
# creating a master dataset for both population and studies data
pop_epi_studies_data <- aqli_color_grp_pm2.5_buckets %>%
left_join(epi_num_studies_grp_pm2.5_buckets, by = c("region", "order_pollution_group")) %>%
select(region,  order_pollution_group, tot_pop_prop, tot_studies_prop) %>%
pivot_longer(cols = tot_pop_prop:tot_studies_prop, names_to = "type_of_prop", values_to = "val")
# plotting the bar graph
pop_num_studies_in_pollution_buckets_graph <- pop_epi_studies_data %>%
ggplot() +
geom_col(mapping = aes(x = fct_reorder(region, order_pollution_group), y = val, fill = type_of_prop), position = position_dodge(), width = 0.7) +
scale_y_continuous(breaks = seq(0, 100, 10)) +
scale_fill_manual(values = c("tot_pop_prop" = "grey", "tot_studies_prop" = "cornflowerblue"), labels = c("Proportion of World Population in Bucket", "Proportion of Studies Completed in Bucket")) +
labs(x = "Mean PM2.5 bucket (in µg/m³)",  y = "Percentage", fill = "") +
theme_hc() +
theme(axis.line.y = element_line(color = "black"),
axis.line.x = element_line(color = "black"))
pop_num_studies_in_pollution_buckets_graph
# adding an order panel
continent_wise_study_duration_graph <- epi %>%
dplyr::filter(continent != "NA", !is.na(continent), duration != "NA", !is.na(duration)) %>%
group_by(paper_uid, continent) %>%
summarise(duration_count = n()) %>%
ungroup() %>%
mutate(order_continent = ifelse(continent == "Asia", 1, 0),
order_continent = ifelse(continent == "Europe", 2, order_continent),
order_continent = ifelse(continent == "North America", 3, order_continent),
order_continent = ifelse(continent == "South America", 4, order_continent),
order_continent = ifelse(continent == "Africa", 5, order_continent),
order_continent = ifelse(continent == "Oceania", 6, order_continent)) %>%
ggplot() +
geom_histogram(mapping = aes(x = study_duration, fill = study_count), alpha = 0.5, color = "white", position = "identity", binwidth = 2) +
labs(x = "Study Duration") +
ggtitle("Epi Studies Duration Distribution (Continent Wise): Histogram") +
scale_x_continuous(breaks = seq(0, 40, 10)) +
theme_hc() +
theme(legend.title = element_blank()) +
facet_wrap(~fct_reorder(continent, order_continent), nrow = 1) +
theme(axis.line.y = element_line(color = "black"),
axis.line.x = element_line(color = "black"))
# adding an order panel
continent_wise_study_duration_graph <- epi %>%
dplyr::filter(continent != "NA", !is.na(continent), study_duration != "NA", !is.na(study_duration)) %>%
group_by(paper_uid, continent) %>%
summarise(duration_count = n()) %>%
ungroup() %>%
mutate(order_continent = ifelse(continent == "Asia", 1, 0),
order_continent = ifelse(continent == "Europe", 2, order_continent),
order_continent = ifelse(continent == "North America", 3, order_continent),
order_continent = ifelse(continent == "South America", 4, order_continent),
order_continent = ifelse(continent == "Africa", 5, order_continent),
order_continent = ifelse(continent == "Oceania", 6, order_continent)) %>%
ggplot() +
geom_histogram(mapping = aes(x = study_duration, fill = study_count), alpha = 0.5, color = "white", position = "identity", binwidth = 2) +
labs(x = "Study Duration") +
ggtitle("Epi Studies Duration Distribution (Continent Wise): Histogram") +
scale_x_continuous(breaks = seq(0, 40, 10)) +
theme_hc() +
theme(legend.title = element_blank()) +
facet_wrap(~fct_reorder(continent, order_continent), nrow = 1) +
theme(axis.line.y = element_line(color = "black"),
axis.line.x = element_line(color = "black"))
continent_wise_study_duration_graph
# adding an order panel
continent_wise_study_duration_graph <- epi %>%
dplyr::filter(continent != "NA", !is.na(continent), study_duration != "NA", !is.na(study_duration)) %>%
group_by(paper_uid, continent) %>%
summarise(duration_count = n()) %>%
ungroup() %>%
mutate(order_continent = ifelse(continent == "Asia", 1, 0),
order_continent = ifelse(continent == "Europe", 2, order_continent),
order_continent = ifelse(continent == "North America", 3, order_continent),
order_continent = ifelse(continent == "South America", 4, order_continent),
order_continent = ifelse(continent == "Africa", 5, order_continent),
order_continent = ifelse(continent == "Oceania", 6, order_continent)) %>%
ggplot() +
geom_histogram(mapping = aes(x = study_duration, fill = duration_count), alpha = 0.5, color = "white", position = "identity", binwidth = 2) +
labs(x = "Study Duration") +
ggtitle("Epi Studies Duration Distribution (Continent Wise): Histogram") +
scale_x_continuous(breaks = seq(0, 40, 10)) +
theme_hc() +
theme(legend.title = element_blank()) +
facet_wrap(~fct_reorder(continent, order_continent), nrow = 1) +
theme(axis.line.y = element_line(color = "black"),
axis.line.x = element_line(color = "black"))
continent_wise_study_duration_graph
epi
# adding an order panel
continent_wise_study_duration_graph <- epi %>%
dplyr::filter(continent != "NA", !is.na(continent), study_duration != "NA", !is.na(study_duration)) %>%
group_by(paper_uid, continent) %>%
summarise(average_study_duration = mean(study_duration, na.rm = TRUE)) %>%
ungroup() %>%
mutate(order_continent = ifelse(continent == "Asia", 1, 0),
order_continent = ifelse(continent == "Europe", 2, order_continent),
order_continent = ifelse(continent == "North America", 3, order_continent),
order_continent = ifelse(continent == "South America", 4, order_continent),
order_continent = ifelse(continent == "Africa", 5, order_continent),
order_continent = ifelse(continent == "Oceania", 6, order_continent)) %>%
ggplot() +
geom_histogram(mapping = aes(x = average_study_duration, fill = continent), alpha = 0.5, color = "white", position = "identity", binwidth = 2) +
labs(x = "Study Duration") +
ggtitle("Epi Studies Duration Distribution (Continent Wise): Histogram") +
scale_x_continuous(breaks = seq(0, 40, 10)) +
theme_hc() +
theme(legend.title = element_blank()) +
facet_wrap(~fct_reorder(continent, order_continent), nrow = 1) +
theme(axis.line.y = element_line(color = "black"),
axis.line.x = element_line(color = "black"))
continent_wise_study_duration_graph
####  PM2.5 distributions of the lower limits and upper limits of exposure range (Density and Histogram Plots)
## All graphs below this block of code is deactivated for the blog post. This will be displayed on the dashboard, alongside other graphs.
#> Specific to PM2.5 and count separate countries in a pooled study separately
#> exposure distribution density and histogram plots (PM2.5 LL and PM2.5 UL)
# create long dataset
epi_long <- epi %>%
filter(!is.na(mean_pm2.5), mean_pm2.5 != "NA", non_pm2.5 == 0) %>%
pivot_longer(cols = contains("pm2.5_exposure"), names_to =  "exposure_type", values_to = "exposure_value") %>%
select(exposure_type, exposure_value) %>%
filter(!is.na(exposure_value))
# density plot
epi_long %>%
ggplot() +
geom_density(mapping = aes(x = exposure_value, fill = exposure_type), alpha = 0.6, position = "identity") +
labs(x = expression(paste("PM2.5 concentration (", mu, "g", "/", m^3, ")"))) +
theme_tufte()
# histogram plot
epi_long %>%
ggplot() +
geom_histogram(mapping = aes(x = exposure_value, fill = exposure_type), position = "identity", alpha = 0.4, color = "white") +
labs(x = expression(paste("PM2.5 concentration (", mu, "g", "/", m^3, ")"))) +
theme_tufte()
# histogram plot
epi_long %>%
ggplot() +
geom_histogram(mapping = aes(x = exposure_value, fill = exposure_type), position = "identity", alpha = 0.4, color = "white") +
labs(x = expression(paste("PM2.5 concentration (", mu, "g", "/", m^3, ")"))) +
theme_tufte()
# create long dataset
epi_long <- epi %>%
filter(!is.na(mean_pm2.5), mean_pm2.5 != "NA", non_pm2.5 == 0) %>%
pivot_longer(cols = contains("pm2.5_exposure"), names_to =  "exposure_type", values_to = "exposure_value") %>%
select(exposure_type, exposure_value) %>%
filter(!is.na(exposure_value))
epi_long
# create long dataset
epi_long <- epi %>%
filter(!is.na(mean_pm2.5), mean_pm2.5 != "NA", non_pm2.5 == 0) %>%
pivot_longer(cols = contains("pm2.5_exposure"), names_to =  "exposure_type", values_to = "exposure_value") %>%
select(paper_uid, exposure_type, exposure_value) %>%
filter(!is.na(exposure_value))
epi_long
# density plot
epi_long %>%
group_by(paper_uid, exposure_type) %>%
summarise(exposure_value = ifelse(exposure_type == "pm2.5_exposure_ll", min(exposure_value, na.rm = TRUE), max(exposure_value, na.rm = TRUE))) %>%
ggplot() +
geom_density(mapping = aes(x = exposure_value, fill = exposure_type), alpha = 0.6, position = "identity") +
labs(x = expression(paste("PM2.5 concentration (", mu, "g", "/", m^3, ")"))) +
theme_tufte()
# histogram plot
epi_long %>%
ggplot() +
geom_histogram(mapping = aes(x = exposure_value, fill = exposure_type), position = "identity", alpha = 0.4, color = "white") +
labs(x = expression(paste("PM2.5 concentration (", mu, "g", "/", m^3, ")"))) +
theme_tufte()
# density plot
epi_long %>%
group_by(paper_uid, exposure_type) %>%
summarise(exposure_value = ifelse(exposure_type == "pm2.5_exposure_ll", min(exposure_value, na.rm = TRUE), max(exposure_value, na.rm = TRUE))) %>%
ggplot() +
geom_density(mapping = aes(x = exposure_value, fill = exposure_type), alpha = 0.6, position = "identity") +
labs(x = expression(paste("PM2.5 concentration (", mu, "g", "/", m^3, ")"))) +
theme_tufte()
# density plot
epi_long %>%
group_by(paper_uid, exposure_type) %>%
summarise(exposure_value = ifelse(exposure_type == "pm2.5_exposure_ll", min(exposure_value, na.rm = TRUE), max(exposure_value, na.rm = TRUE))) %>%
ggplot() +
geom_density(mapping = aes(x = exposure_value, fill = exposure_type), alpha = 0.6, position = "identity") +
labs(x = expression(paste("PM2.5 concentration (", mu, "g", "/", m^3, ")"))) +
theme_tufte()
# histogram plot
epi_long %>%
group_by(paper_uid, exposure_type) %>%
summarise(exposure_value = ifelse(exposure_type == "pm2.5_exposure_ll", min(exposure_value, na.rm = TRUE), max(exposure_value, na.rm = TRUE))) %>%
ggplot() +
geom_histogram(mapping = aes(x = exposure_value, fill = exposure_type), position = "identity", alpha = 0.4, color = "white") +
labs(x = expression(paste("PM2.5 concentration (", mu, "g", "/", m^3, ")"))) +
theme_tufte()
#> (5) age distribution plot (LL and UL) using the long dataset (density plot)
epi_long_age_dist <- epi %>%
filter(((!is.na(cohort_age_ll)) | (cohort_age_ll != "NA")) & ((!is.na(cohort_age_ul)) | (cohort_age_ul != "NA"))) %>%
pivot_longer(cols = contains("cohort_age"), names_to =  "age_dist_type", values_to = "age_value") %>%
select(paper_uid, age_dist_type, age_value) %>%
filter(!is.na(age_value))
epi_long_age_dist %>%
ggplot() +
geom_density(mapping = aes(x = age_value, fill = age_dist_type), alpha = 0.6, color = "black") +
labs(x = "Age") +
theme_tufte()
#> (6) age distribution plot (LL and UL) using the long dataset (histogram plot)
epi_long_age_dist %>%
ggplot() +
geom_histogram(mapping = aes(x = age_value, fill = age_dist_type), alpha = 0.5, position = "identity", color = "white") +
labs(x = "Age") +
theme_tufte()
#> (7) Country Wise Cohort Size density plot
epi %>%
filter(cohort_size != "NA", !is.na(cohort_size)) %>%
ggplot() +
geom_density(mapping = aes(x = log10(cohort_size), fill = country), alpha = 0.5) +
theme_tufte()
#> (8) Country wise Cohort Size histogram plot
epi %>%
filter(cohort_size != "NA", !is.na(cohort_size)) %>%
ggplot() +
geom_histogram(mapping = aes(x = log10(cohort_size), fill = country), alpha = 0.5, position = "identity") +
theme_tufte()
